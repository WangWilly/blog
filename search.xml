<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Artificial Neural Networks 類神經網路學習]]></title>
    <url>%2Fblog%2F2018%2F04%2F25%2FArtificial-Neural-Networks-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E5%AD%B8%E7%BF%92%2F</url>
    <content type="text"><![CDATA[Artificial Neural Networks 類神經網路概論( 未完成 ) 簡介類神經網絡是一種受生物學啟發而產生的一種模擬人腦的學習系統。 Youtube - 介紹神經元與類神經的關係 ↑ 神經元示意圖( *synapse：比重 ) 對於神經(neuron)我們有一個簡單的抽象：每個神經元是與其他神經元連結在一起的，一個神經元會受到多個其他神經元狀態的衝擊，並由此決定自身是否激發。 神經細胞透過輸入神經樹由其它神經細胞輸入脈波訊號後，經過神經細胞核的處理，其處理大約是： 將收集到的訊號作加總 非線性轉換 產生一個新的脈波信號 如果這個訊號夠強，則新的脈波信號會由神經軸傳送到輸出神經樹，再透過神經節將此訊號傳給其它神經細胞。值得注意的是：當訊號經過神經節後，由於神經節加權值的影響，其訊號大小值會改變。 神經網絡裡的結點相互連結決定了輸入的數據在裡面經過怎樣的計算。我們可以通過大量的輸入，讓神經網絡調整它自身的連接情況從而總是能夠得到我們預期的輸出。 ＜比較＞電腦裡的模擬神經網路的架構需具備： 模擬頭腦神經的連結( 包含模擬突觸、細胞本體( 隱藏層 )、軸突 ) 每個神經節點 實數的輸入與輸出 極大量的資訊 遷移學習( Transfer learning ) 基礎概念 - 周莫烦 - 站在巨人的肩膀上, 迁移学习 Transfer Learning 實際應用( Python ) - 周莫烦 - 迁移学习 Transfer Learning 什么是迁移学习 (Transfer Learning)？这个领域历史发展前景如何？感知器 ( Perceptron )設有 $n$ 維輸入的單個感知機( 從其他類神經元接收到的資訊 )，$a_1$ 至 $a_n$ 為 $n$ 維輸入向量的各個分量，$w_1$ 至 $w_n$ 為各個輸入分量連接到感知機的權值( 比重 )，$w_0$ 為偏置( 常數 )，一個神經元( Cell Body )分成兩個步驟，第一個 $\sum$ 為彙總資料，後面那個 $f(.)$ 為傳遞函數( 圖上的函數是&quot;Sign function&quot; )，判斷最後輸出的值， 最後以純量輸出( 1 or -1 )。 $$Input: x_1, x_2, …,x_n$$ $$Output: 1 or -1$$ 類神經元示意圖 ＜注意＞$w_0$不是伴隨其他的資訊傳進神經元的，而是因為某些演算法的需求，而另外多加的一個閾值( 正負常數值 )。 $ \sum_{i = 0}^n W_i X_i$又稱為淨輸入( Net Input )，可處理線性組合的假說空間( Hypotheses )。 上圖為此神經元判斷的觸發函數( 每個神經元的判斷都不盡相同，此為其中一種 )，帶入剛剛所算的淨輸入，計算輸出( -1就是判斷為無反應的狀況 )。 權值($w$)：如果當前神經元的某個輸入值權值為零，則當前神經元激發與否與這個輸入值無關；如果某個輸入值的權重為正，它對於當前神經元的激發值產生正影響。反之，如果權重為負，則它對激發值產生負影響。 偏移量($w_0$)：它定義了神經元的激發臨界值在空間上，它對決策邊界(decision boundary) 有平移作用，就像常數作用在一次或二次函數上的效果。感知器表示為輸入向量與權向量內積時，偏置被引申為權量，而對應的輸入值為 1。 決策邊界(decision boundary)：設輸入向量與權向量的內積為零，可得出 n+1 維的超平面。平面的法向量為 w，並經過 n+1 維輸入空間的原點。法向量指向的輸入空間，其輸出值為+1，而與法向量反向的輸入空間，其輸出值則為−1。故可知這個超平面定義了決策邊界，並把輸入空間劃分為二。 激勵函數(activation function)：激勵函數代表神經元在什麼輸入情況下，才觸發動作。 感知器可以「學習」的函數 Consider a 2-input perceptron ( 感知器 ) : It outputs 1 iff $$o( x_1, x_2 ) = ( w_0+w_1 \cdot x_1+w2 \cdot x2 &gt; 0 )? $$ equivalent to $$o( x_1, x_2 ) = sgn( w_0+w_1 \cdot x_1+w2 \cdot x2 )$$ What weights represent $AND (x1, x2)$?$w_0 = -0.8, w_1 = w_2 = 0.5$ $o( x_1, x_2 ) \Rightarrow sgn(-0.8 + 0.5 \cdot x_1 + 0.5 \cdot x_2 )$ What weights represent $OR (x1, x2)$?$w_0 = 0.3, w_1 = w_2 = 0.5$ $o( x_1, x_2 ) = sgn(0.3 + 0.5 \cdot x1 + 0.5 \cdot x2 )$ What weights represent $NOT (x1, x2)$?$w_0 =0.0, w_1 = -1.0, w_2 = 0$ $o(x_1) = sgn( 0.0 –1.0x_1)$ What weights represent $XOR (x1, x2)$?Not possible. ＜NOTE＞Not linearly separable $\rightarrow$ Can not be represented by a single percepton. Solution: use multilayer networks. How to Determine a Weight Vector? 如何決定權重向量？ 在類神經網路學習的過程中，最重要的就是權重向量( Weight Vector )，因為這就是決定到時候感知器( Perceptrons )能不能做出正確預測( correct $\pm 1$ output )的關鍵依據。 通常來說，都會給定一組訓練範例( Trainning example )，而且，每個元素裡必定會含有輸入( Input )與輸出( Output )。 $( x_1, x_2, x_3, \ldots , x_{n-1}, x_n )$ 是訓練範例中會給的資訊。 $+1 \; or \; -1$ 為 $( x_1, x_2, x_3, \ldots , x_{n-1}, x_n )$ 的已知輸出( Target value )。 而我們的目標就是將 $( w_1, w_2, w_3, \ldots , w_{n-1}, w_n )$ 訓練出來。 解決的演算法有很多，在這邊只討論其中兩個： The perception trainnin rule Gradient decent ( or call the delta rule ) Perceptron Training Rule $t = c(x_1, x_2, x_3, ..., x_n )$ 是我們已知道的結果( 1 or -1 )。 $o：$對於訓練資料$ (x_1, x_2, x_3, ..., x_n ) $以感知器( Perceptron )測試後出來的結果( 1 or -1 )。 ＜Note＞：Here o is the output of Perceptron, not the target value. 所以 $ ( t - o ) $ 為此時感知器( Perceptron )的誤差，然後藉由我們設定的 $\eta$ 函式判斷要對目前的 $w$ 修正多少值。 演算法 Initialize weights (w0, w1, w2, x3, ...,wn ) to random values Loop through training examples： $w_i \leftarrow w_i + \Delta w_i$ Where $\Delta w_i = \eta (t-o) \cdot x_i$ and $\eta$ is a learning rate (small positive value, e.g., 0.1) Given training data set $$D = { ( \vec{x}, t ) }$$ 123456789//Initialize all weights w_i to random valuesw[] &lt;- random valuesWHILE not all examples correctly predicted DO FOR each training example x = (x_1, x_2, x_3, ..., x_n ) in D Compute current output o ( x_1, x_2, x_3, ..., x_n ) FOR i = 0 to n // always let x_0=1 w_i w_i + eta(t - o) * x_i ＜Note＞ If (t-o) = 0, no change in weight. 輪過一遍所有訓練資料，稱之為一個時代( Epoch )，若一個時代過後還有 $w_i$ 是錯誤的就繼續修改 $w_i$ ，直到某個時代所有的 $ w_i $ 可以讓 $ x_i $ 輸出正確。 ＜注意＞：如果訓練資料是線性可分離( XOR就不可線性分離 )，且$\eta$是小於1的很小的值，那麼一定最後可以在有限的世代找到最後的感知器( Perceptron )。 倘若今天的資料是無法被線性分離的改如何處理？ Approach 1: 建立一個演算法可以努力找到逼近值。 E.g. gradient descent method ( 梯度下降法 ) Approach 2: 建立不同架構或多層( Multilayer networks )結構的神經網路以突破限制。 Gradient DescentYoutube - Gradient Decent 介紹 我們需要在 $(n+1)$ 維的假說向量空間( Hypotheses Space )中搜索最合適( Best fit )的權值向量，我們需要有一定的規則指導我們的搜索，採用沿著梯度反方向往下走的方法，就稱為「梯度下降法」(Gradient Descent)。這種方法可以說是一種「貪婪演算法」(Greedy Algorithm)，因為它每次都朝著最陡的方向走去，企圖得到最大的下降幅度。即使訓練資料是不可線性分離的( Not lineary separable )，最後這個演算法還是會收斂在極趨近於目標想法的銓重向量停止。 ＜注意＞： Least square為最常用來檢測誤差的方法。 為了要計算梯度，我們不能採用不可微分的 sign() 步階函數，因為這樣就不能用微積分的方式計算出梯度了，而必須改用可以微分的連續函數 sigmoid()，這樣才能夠透過微分計算出梯度。 $$E(w) = \frac{1}{2} \sum_{d \in D} ( t_d - o_d )$$ 上面公式中$D$代表了所有的輸入案例( 或者說是樣本 )，$d$代表了一個樣本實例，$o_d$表示感知器的輸出，$t_d$代表我們預想的輸出。 首先，我們先看看權重( Weight vector )向量 $w$ 的梯度( Gradient )為何： $$\bigtriangledown E( w ) = \frac{\partial E}{\partial w} = ( \frac{\partial E}{\partial w_0}, \frac{\partial E}{\partial w_1}, \ldots, \frac{\partial E}{\partial w_n} )$$ ＜注意＞： 梯度 是一個裡面所有元素為對 $E$ 以對每個 $w_i$ 偏微分的向量。且這個向量指向的地方為最上坡之處。( 如下圖紅色處顯示，而下方黑色箭頭則表示該梯度投影下來所對應的方向 ) 所以 Gradient Descent 就是該點梯度的 反方向 ，也就是最下坡的方向，$i.e. \; -\bigtriangledown E(w)$。 這樣目標就明確了，欲在假說空間找到一組權值 $w$ 讓這個誤差的值最小，顯然我們用誤差對權值求導將是一個很好的選擇，導數的意義是提供了一個方向，沿著這個方向改變權值，將會讓總的誤差變大，更形象的叫它為梯度。 既然梯度確定了E最陡峭的上升的方向，那麼梯度下降的訓練法則是： $$\vec{w_i} \leftarrow \vec{w_i} + \Delta \vec{w_i}, \quad where \; \Delta \vec{w_i} = \eta \frac{\partial E}{\partial w_i}$$ $E.x.$ Example: two weights: $w = (w_0, w_1)$ Error surface $E$ is parabolic (by definition) Single global minimum Arrow: negated gradient at one point Steepest descent along the surface For the least square error function, gradient is easy to calculate: $$\bigtriangledown E( w ) = \frac{\partial E}{\partial w} = \frac{1}{2} \cdot \frac{\partial \sum_{d \in D} (t_d - o_d)^2}{\partial w_i} = \frac{1}{2} \sum_{d \in D}\frac{\partial (t_d - o_d)^2}{\partial w_i} $$ $$\Rightarrow \frac{1}{2} \cdot \sum_{d \in D} (2 \cdot (t_d - o_d)\frac{\partial( t_d - o_d )}{\partial w_i}) = \sum_{d\in D}((t_d - o_d)\frac{\partial(t_d - w\cdot x_d)}{\partial w_i})$$ $$ \Rightarrow \sum_{d\in D} ((t_d - o_d)(-x_{id}))$$ 依上述，公式就可以簡化成： $$\Delta w_i = -\eta \frac{\partial E}{\partial w_i}$$ $$and$$ $$\frac{\partial E}{\partial w_i} = \sum_{d \in D}((t_d - o_d)(-x_{id}))$$ 最後公式變成： 參考 Mr&#39; opengate - AI - Ch16 機器學習(4), 類神經網路 Neural network Wikipedia - 人工神經網路 基礎概念 - 周莫烦 - 站在巨人的肩膀上, 迁移学习 Transfer Learning 實際應用( Python ) - 周莫烦 - 迁移学习 Transfer Learning 什么是迁移学习 (Transfer Learning)？这个领域历史发展前景如何？]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Artificial Neural Networks</tag>
        <tag>Gradient Decent</tag>
        <tag>Perceptron trainning rule</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Supervised learning 監督式學習 - Concept Learning 概念學習]]></title>
    <url>%2Fblog%2F2018%2F04%2F20%2FSupervised-learning-%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92-br-Concept-Learning-%E6%A6%82%E5%BF%B5%E5%AD%B8%E7%BF%92%2F</url>
    <content type="text"><![CDATA[Supervised learning 監督式學習 - Concept Learning 概念學習 機器學習簡介( 節錄自 Mr&#39; OpenGate )機器學習是近20多年興起的一門多領域交叉學科，涉及機率論、統計學、逼近論、凸分析、計算複雜性理論等多門學科。機器學習理論主要是設計和分析一些讓計算機可以自動「學習」的演算法。機器學習算法是一類從資料中自動分析獲得規律，並利用規律對未知資料進行預測的算法。 機器學習已廣泛應用於數據挖掘、計算機視覺、自然語言處理、生物特徵識別、搜尋引擎、醫學診斷、檢測信用卡欺詐、證券市場分析、DNA序列測序、語音和手寫識別、戰略遊戲和機器人等領域。 ＜定義＞ 機器學習定義如下 A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E. $Ex.$ T(任務)：將郵件分類為垃圾或非垃圾。 E(經驗)：觀察目前信箱的信是把哪些種類的郵件標記為垃圾，而哪些是非垃圾。 P(效能)：被正確分類成垃圾或非垃圾的郵件的數量。 一種歸納的方式 從已知的現象訓練機器判斷常態的結果，而已知的現象只有是非之結論。(所以用這個方法訓練出來的智能只能判斷對錯) 所以以這種方法訓練的智能我們可以看待它是一個布林函數(Boolean-valued Funciotn)。 輸入 - 欲判斷的狀態 (Attributes)。 輸出 - 對(TURE)、錯(FALSE)。 環境狀態( Attribute )、學習目標( Target Concept )Example from book：Enjoy sport 六個會影響的環境狀態 ( Attribute ) 四個案例 ( Instance ) 學習目標：判斷當時是否很享受運動。$EnjoySport = {Yes, No}$ 環境狀態( Attribute ) 每個事件(instance)發生時會引響結果的基本元素。 倘若現在有一事件會被影響的環境狀態為 $N$ 個。 每個環境狀態可能出現的狀態個數為 $n_i$ 。(第 $i$ 個環境狀態) (Nominal values; symbolic values; Discretized values)(? 待了解) 案例( Instance ) - 已知結果的一群環境狀態 令 $x$ 為已知結果的一群環境狀態。 那我們稱所有可能產生的案例為一個空間(Space)並稱它 $X$。 若 $M$ 等於此空間 $X$ 的大小，則 $ M = n_1 \cdot n_2 \ldots n_{N-1} \cdot n_N$。 我們其實可以將 $M$ 視為此環境狀態所有組合的方法數。 學習目標( Target Concept ) 要學到的想法(在這裡我們給機器訓練的想法也可視為一個函式)。 $c(x)=1 \qquad if \; EnjoySport=Yes$ $c(x)=0 \qquad if \; EnjoySport=No$ $c$ 是一個定義再案例空間(Instance Space)的布林函數。 $c:X \rightarrow { 0, 1 }$ 訓練集合 &quot;$D$&quot; 所有已知想法的案例集合 $Ex.$ $$&lt;x_1, c(x_1)&gt;, &lt;x_2, c(x_2)&gt; \ldots &lt;x_m, c(x_m)&gt;$$ 假說( Hypotheses ) - 在這裡我們標記為 $H$ 定義：所有環境狀態( Attributes )之限制( Constraints ) 的交集( Conjunction )。 限制( Constraints )的種類 Specific value ( 針對值 ) $\qquad e.g. \; ( sky = sunny )$ Don&#39;t care value ( 不在意值 ) $\qquad e.g. \; ( sky = &quot;？&quot; )$ No value allow ( 無值 ) $\qquad e.g. \; ( sky = &quot;\phi&quot; )$ 若今天有一案例( Instance )符合了我們的假說，也就是說它每個環境狀態( Attributes )全部都不逾越我們假說中的所有限制( Constraints )。 $Ex.$ $$h \leftarrow &lt; Sunny, Warm, ?, Strong, ?, ? &gt;$$ 假說空間( Hypotheses Space )的大小 語意上來說( Syntactically distinct number ) $$M_H = ( n_1 + 2 ) \cdot ( n_2 + 2 ) \cdot \ldots \cdot ( n_{N-1} + 2 ) \cdot ( n_{N} + 2 )$$ $$( Two \; more \; &quot;values&quot; \; have \; been \; added, &quot;?&quot; and &quot;\phi&quot; )$$ 實際上來說( Semantically distinct number ) $$M_H = 1+ ( n_1 + 1 ) \cdot ( n_2 + 1 ) \cdot \ldots \cdot ( n_{N-1} + 1 ) \cdot ( n_{N} + 1 )$$ $$因為如果該假說的限制交集裡，有一個以上的&quot;\phi&quot;存在於集合中，$$ $$代表所有的案例( Instances )絕對都不可能不逾越我們的假說$$ $$，全部的案例都會判定為錯誤(False)。$$ 小節論 $c:EnjoySport : X \rightarrow { 0, 1 }$ 是我們的學習目標( Target Concept )。 六個環境狀態( Attributes )： Sky ( 可能的變數有三種 ) $${ Sunny, Cloudy, Rainy }$$ Airtamp ( 可能的變數有兩種 ) $${ Warm, Cold }$$ Humidity ( 可能的變數有兩種 ) $${ Normal, High }$$ Wind ( 可能的變數有兩種 ) $${ Strong, Light }$$ Water ( 可能的變數有兩種 ) $${ Cold, Warm }$$ Forecast ( 可能的變數有兩種 ) $${ Same, Change}$$ 案例空間的大小 $= 3 \cdot 2 \cdot 2 \cdot 2 \cdot 2 \cdot 2 = 96$ 假說空間的大小 $= 1 + ( 4 \cdot 3 \cdot 3 \cdot 3 \cdot 3 \cdot 3 ) = 973$ ( 實際上 ) 現在知道目前的假說空間大小後，就要開始找到符合我們期望( Target )的假說( Hypotheses )，那要從何先下手呢？首先，我們可以先從現有的訓練資料使用，其中，我們還可以了解一個概念－－－Inductive learning hypothesis，意思是說，我們今天使用訓練的資訊來找到一個最靠近的假說時，我們也可以找到一些潛在的的規則包含在我們找到的假說之中，其中會有我們從為訓練過的案例( Instance )在內。 ＜注意＞：在實務上來說，有可能訓練的難度會急遽上升，有可能我們的假說空間會超級大，甚至於無限大也有可能，所以要一個個要從所有的假說找到我們需要的是不太可能的，那怎麼辦呢？我們可以利用假說空間的一個特性－－－Partial Ordering，也就是說，這個空間裡的元素，是可以依照一個順序大小排列的。 假說空間的廣至收斂General-to-Specific Ordering over Hypotheses首先定義幾個名詞，我們有： 案例( Instance )：$x$ 假說( Hypothesis )：$h$ 若今天 $h(x) = 1$ ，稱之 Positive ( True ) Outcome。 由廣至收斂，定義若 $H_1 \geq_g H_2$，則可以說 $H_1$ 比 $H_2$還要更廣( General )，舉例： $${ Sunny, ?, ?, ?, ?, ? } \geq_g { Sunny, ?, ?, Strong, ?, ? } $$ Find S Algorithm 將假說 $h$ 初始化為假說空間 $H$ 中的最特殊假說 ${ \phi, \phi, \phi, \phi, \phi, \phi } $ 對每個正例 $x$ ( ＜注意＞我們只使用正例( Positive Outcome )，不用反例！ ) 對 $h$ 的每個環境狀態( Attribute )進行約束 如果 $x$ 的該環境狀態滿足 $h$ 對應的環境狀態，那麼不做任何處理。 否則將 $h$ 中該環境狀態一般化( Generalize ) 以滿足 $x$ 的環境狀態。 重複直到所有正例都被尋遍。 輸出最後唯一的假說 $h$ ，而這個假說正是我們使用訓練資料中的正例所能訓練出最收斂的假說。 Version SpaceDefinition: Consistent Hypotheses( 認同假說 )若有假說 $h$ 以訓練集合所有的案例進行測試，輸出結果和我們的想法一致，就可以聲明假說 $h$ 為認同假說( Consistent Hypotheses )。( 下方為原始定義 ) A hypothesis $h$ is consistent with a set of training examples $D$ of target concept $c$ if and only if $h(x) = c(x)$ for each training example $&lt;x, c(x)&gt;$ in $D$. $$ Consistent (h, D) \equiv ( \; \forall &lt;x, c(x ) \in D \;) h(x) = c(x) $$ Definition: Version Space ( 候選空間 )候選空間就是對於該測試的資料集，所有的認同假說所組合的空間，因為每個假說都可以符合目前的訓練資料的期望，所以每個假說都等待我們再進一步驗證。( 下方為原始定義 ) The version space $VS_{H,D}$ , with respect to hypothesis space $H$ and training examples $D$, is the subset of hypotheses from $H$ consistent with all training examples in $D$. $$ VS_{H,D} \equiv { h \in H \; | \; Consistent (h, D) } $$ Version space for a &quot;rectangle&quot; hypothesis language in two dimensions. Green pluses are positive examples, and red circles are negative examples. GB is the maximally general positive hypothesis boundary, and SB is the maximally specific positive hypothesis boundary. The intermediate (thin) rectangles represent the hypotheses in the version space. Definition: General Boundary General boundary $G$ of version space VS_{H,D} : set of most general members Definition: Specific Boundary Specific boundary $S$ of version space VS_{H,D} : set of most specific members Version Space Every member of the version space lies between $S$ and $G$ $$VS_{H,D} \equiv { h \in H \; | \; (\exists s \in S ) (\exists g \in G ) (g \geq_g h \; \geq_g s) } $$ $$where \geq_g \equiv more \; general \; than \; or \; equal \; to$$ The List-Then-Elimination Algorithm列表消除演算法 起始化： 候選空間( Version Space ) $\leftarrow(assign)$ 所有在假說空間的假說。 對每個訓練案例$&lt;x, c(x)&gt;$ 從候選空間消除所有 $h(x) \neq c(x)$ 的假說 $h$。 對所有的訓練案例檢驗過，最後輸出候選空見剩下的假說列表。 優點保證最後的假說列表裡的所有假說必定和訓練案例的期望相符( Consistent )。 缺點 若今天假說空間是無窮大，那這個方法就不能使用。 要將該假說空間的所有假說窮舉於列表之中。 Candidate-Elimination Algorithm候選消除演算法＜前情提要＞：候選空間( Version Space )可以由 Most specific boundaries 與 Most general boundaries 界定出來。 正例可以將 Specific boundary 變的更一般化( General )。 Positive examples force specific boundary to become more general. 反例可以將 General boundary 變的更收斂( Specific )。 Negative examples force general boundary to become more specific. 最後，這個界定出來的假說集合可以符合所有的訓練資料。 In the end, all hypotheses which satisfy training data remain. 起始化 G $\leftarrow$ 一組在假說空間 $H$ 最一般化的環境因素。標記為：$&lt;?, \ldots, ?&gt;$ S $\leftarrow$ 一組在假說空間 $H$ 最嚴苛的環境因素。標記為：$&lt;\phi, \ldots, \phi&gt;$ 對於每個訓練案例 $d$，進行以下操作： 若 $d$ 為一正例： 從 $G$ 中移除所有與 $d$ 不一致的假說。 對 $S$ 中每個對 $s$ 不一致的假說$s$： 將 $s$ 從 $S$ 之中移去。 把 $s$ 的所有的極小泛化假說 $h$ 加入到S中，其中 $h$ 滿足 $h$與$d$一致，且$G$的其中一個元素必比起 $h$ 更泛化。 從$S$中移去所有符合這樣的假說：它比S中另一假設更泛化。 若 $d$ 為一反例： 從 $S$ 中移去所有 $d$ 不一致的假說。 對 $G$ 中每個與 $d$ 不一致的假設 $g$： 從 $G$ 中移去 $g$ 。 把 $g$ 的所有的極小特化式 $h$ 加入到 $G$ 中，其中 $h$ 滿足 $h$ 與 $d$ 一致，而且 $S$ 的某個成員比 $h$ 更收斂。 從 $G$ 中移去所有符合這樣的假說：它比 $G$ 中另一假說更特殊。 範例 - $EnjoySport$起始化Specific boundary to: $S_0 = {(Ø,Ø,Ø,Ø,Ø,Ø)}$ General boundary to: $G_0 = {(?,?,?,?,?,?) }$ 1’st instance: (Sunny,Warm,Normal,Strong,Warm,Same) = YesPositive example generalizes Specific boundary $S_1 = { (Sunny,Warm,Normal,Strong,Warm,Same) }$ $G_1 = { (?,?,?,?,?,?) }$ 2’nd instance: (Sunny,Warm,High,Strong,Warm,Same) = YesPositive example generalizes Specific boundary $S_2 = {(Sunny,Warm,?,Strong,Warm,Same) }$ $G2 = { (?,?,?,?,?,?) }$ 3’rd instance: (Rainy,Cold,High,Strong,Warm,Change) = NoNegative example specializes General boundary $S_3 = \left{ (Sunny,Warm,?,Strong,Warm,Same) \right}$ $G_3 = { (Sunny,?,?,?,?,?), \quad O.K.$ $(Cloudy,?,?,?,?,?), \quad Not \; more \; general \; than \; S_3$ $(?,Warm,?,?,?,?), \quad O.K.$ $(?,?,Normal,?,?,?), \quad Not \; more \; general \; than \; S_3$ $(?,?,?,Light,?,?), \quad Not \; more \; general \; than \; S_3$ $(?,?,?,?,Cool,?), \quad Not \; more \; general \; than \; S_3$ $(?,?,?,?,?,Same)} \quad O.K.$ $\Rightarrow G_3 = { (Sunny,?,?,?,?,?), (?,Warm,?,?,?,?), (?,?,?,?,?,Same)}$ 4’th instance: (Sunny,Warm,High,Strong,Cool,Change) = YesPositive example generalizes Specific boundary $S_4 = { (Sunny,Warm,?,Strong,?,?) }$ $G_4 = { (Sunny,?,?,?,?,?), (?,Warm,?,?,?,?) }$ Final version space is all hypotheses, h such that: $$g \geq_ g h \; \geq_g s$$ What query should the learner make next? How should these be classified? &lt;Sunny, Warm, Normal, Strong, Cool, Change&gt; &lt;Rainy, Cold, Normal, Light, Warm, Same&gt; &lt;Sunny, Warm, Normal, Light, Warm, Same&gt; Inductive Bias 歸納偏置 ( 未完待補 )需要某些的預先設定( 偏見 )。 參考 Mr&#39; OpenGate - AI - Ch13 機器學習(1), 機器學習簡介與監督式學習 Introduction to Machine Learning, Supervised Learning 《机器学习》第2章中find-s算法的python实现 WEKIPEDIA - Version space learning robert_ai - ML一（概念学习和一般到特殊序）]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Concept Learning</tag>
        <tag>Supervised Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[機器學習地圖]]></title>
    <url>%2Fblog%2F2018%2F04%2F20%2F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E5%9C%B0%E5%9C%96%2F</url>
    <content type="text"><![CDATA[機器學習地圖 類別 監督學習 (Supervised learning)：從給定的訓練數據集中學習出一個模式（函數 / learning model），當新的數據到來時，可以根據這個模式預測結果。監督學習的訓練集要求是包括輸入和輸出，也可以說是特徵和目標。訓練集中的目標是由「人」標註的。常見的監督學習算法包括回歸分析和統計分類( Classify )。 無監督學習 (unsupervised learning)：與監督學習相比，訓練集沒有人為標註的結果。常見的無監督學習算法有聚類( Cluster )。 半監督學習 (Semi-supervised learning)：介於監督學習與無監督學習之間。 增強學習 (reinforcement learning)：通過觀察來學習做成如何的動作。每個動作都會對環境有所影響，學習對象根據觀察到的周圍環境的反饋( 獎勵 )來做出判斷。 機器學習演算法種類 構造條件機率：回歸分析和統計分類 人工神經網絡 決策樹 高斯過程回歸 線性判別分析 最近鄰居法 感知器 徑向基函數核 支持向量機 通過再生模型構造機率密度函數： 最大期望算法 graphical model：包括貝葉斯網和Markov隨機場 Generative Topographic Mapping 近似推斷技術： 馬爾可夫鏈 蒙特卡羅方法 變分法 最優化：大多數以上方法，直接或者間接使用最優化算法。 參考 Mr&#39; OpenGate - AI - Ch13 機器學習(1), 機器學習簡介與監督式學習 Introduction to Machine Learning, Supervised Learning]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Map</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Decision Tree Learning]]></title>
    <url>%2Fblog%2F2018%2F04%2F18%2FDecision-Tree-Learning%2F</url>
    <content type="text"><![CDATA[Decision Tree Learning 決策樹學習 簡介 最受歡迎的歸納推理演算法( inductive inference algorithm )。 廣泛且實務的方法。 對於干擾值( Noise )相當敏感。 可用來學習如何以聯集( Disjunctive )表示限制集( Constraints )。 ( Concept Learning 以交集( Conjunctive )表示 ) 呈現的方式相當簡單。 樹狀結構( Tree Structure )、若則表示式( If-Then rules ) $Ex.$ Play Tennis範例訓練資料( Training Example ) 決策樹( Decision Tree ) 決策樹( Decision Tree )的介紹決策樹表示法( Decision Tree Representation ) 每個內節點 Internal node ( 包括根結點 Root node )代表對一個環境狀態( Attribute )檢驗。 而分支( Branch )出來的意義我們可以視為是該環境狀態( Attribute )的一種可能值( Attribute value )。 每個葉節點 Leaf node 給予一個適當的分類結果( Classification )。 我們將每個案例( Instances )分類到一個離散的類別( Categories )之中。 藉由決策樹由根結點至葉節點找到該類別。 決策樹引導的假說( Hypotheses ) 先 AND 再 OR ( 原文：Disjunctions (OR’s) of conjunctions (AND’s) )。 經由根結點往葉節點走可視為是一種對於該環境狀態限制的交集( Conjunction of constraints on attributes )。 而連上兄弟節點( Sibling )的兩個邊( Edges )可視為是一種對於該環境狀態限制的聯集( Separate branches are disjunctions )。 $Ex \; ( Cont. )$ (Outlook=Sunny and Humidity=Normal) or (Outlook=Overcast) or (Outlook=Rain and Wind=Weak) 注意！ 每個用來訓練的案例 ( Instances )都必須要以「因素-結果」( Attribute - value pairs )的方式給予訓練。 目標訓練函式 ( Target function )的值域是離散的值 ( Discrete value )。 這種方法最後呈現的假說 ( Hypotheses )有可能是一些環境狀態限制( Constraints on attributes )的聯集( Disjunctive )。 極有可能會被不乾淨的資料( Noise )擾亂了學習。 應用於： 醫療或是設備的診斷。 信用額度分析( 銀行 )。 決策樹的種類世界上有許多有特殊的決策樹演算法( decision-tree algorithms )，比較著名的有： ID3 (Iterative Dichotomiser 3) C4.5, C5.0 (successor of ID3) CART (Classification And Regression Tree) CHAID (CHi-squared Automatic Interaction Detector). MARS: extends decision trees to handle numerical data better. 注意 ID3 is the algorithm discussed in textbook.( 在書本中有更詳細的介紹 ) Simple, but representative. ( 簡單但representative? ) Source code publicly available. ( 程式碼是開放的 ) ID3演算法 概述：Top-down, greedy search through space of possible decision trees. ( 在所有可以出現的決策樹中用貪心法由上而下找到較佳的那棵樹。 ) ID3在建構決策樹過程中，以資訊獲利(Information Gain)為準則，並選擇最大的資訊獲利值作為分類屬性。這個算法是建立在奧卡姆剃刀的基礎上：越是小型的決策樹越優於大的決策樹。儘管如此，該算法也不是總是生成最小的樹形結構，而是一個啟發式算法。另外，C4.5算法是ID3的升級版。 Decision trees represent hypotheses, so this is a search through hypothesis space. ( 決策樹亦也代表是一種假說，所以這個演算法也可以說是在所有的假說中找到一個較佳的假說。 ) 那個演算法該如何起手呢？ 決定甚麼環境因素( Attribute )應該放在根結點( Root node )？ 接著由上而下( Top-down )的建構決策樹，對每個後繼的節點( Successive node )使出一樣的決策手段選出該節點應該置入何種環境因素( Attribute )。 注意！千萬不要由下往上參考之前選過的值，因為我們以貪心法則，所以目前的最佳解決不可能出現在之前選過的環境因素( Attribute )之中，或是受其干擾。 ( Never backtracks to reconsider earlier choices. ) 同上述，在每次的選擇之中，由於我們認知這種情況適用貪心法( Greedy Method )，所以我們每次環境因素( Attribute )的選擇都朝向我們最後最佳的假說靠近。 虛擬碼( Pseudo Code )12341. 使用屬性計算與之相關的樣本熵值2. 選取其中熵值最小的屬性(資訊獲利最大)3. 生成包含該屬性的節點4. 遞迴直到終止 ＜討論＞ ID3演算法的終極目標，就是要將決策樹中每個節點都擺上最優的環境因素( Attributes )。 $Question.$ 到底以甚麼條件決定甚麼因素要擺放於哪個節點？ $Answer.$ 資訊獎賞 or 資訊獲利( Information gain )。 資訊獲利( Information gain ) 統計該價值以檢視該環境因素置於何處來分類我們的資料，我們使用熵( entropy 又稱&quot;亂度&quot; )來定義這邊的資訊獲利( Information gain )。( 原文：Statistical quantity measuring how well an attribute classifies the data. Use entropy to define information gain. ) ID3 和 C4.5 - Information gain ( 資訊獲利 ) 與 Gain ratio定義關心其中一個環境因素( Attribute )$A$ 的資訊獲利( Information gain )我們標記為 $Gain( S, A )$，且我們關心的目標樣本群體為 $S$，其中： $$Gain( S, A ) = Entropy( S ) - \sum_{ v \in Values(A) } ( \frac{S_v}{S}Entropy(S_v) )$$ $v$ ranges over values of $A$ $S_v$: members of $S$ with $A = v$ $1^{st}$ term: the entropy of $S$ $2^{nd}$ term: expected value of entropy after partitioning with $A$ Example： PlayTennies 四個環境變因 Outlook = {Sunny, Overcast, Rain} Temperature = {Hot, Mild, Cool} Humidity = {High, Normal} Wind = {Weak, Strong} 欲看討的結果 - 開心或是不開心( Target Attributes - Binary ) PlayTennis = {Yes, No} 今天有14組訓練資料 9筆的結果是開心的 ( Positive ) 5筆的結果是不開心的( Negative ) 訓練資料表 Step 1. 計算整體的亂度( Entropy )$N_\oplus = 9, N_\ominus = 5, N_{Total} = 14$ $Entropy( S ) = -\frac{9}{14} \cdot \lg (\frac{9}{14}) - \frac{5}{14} \cdot \lg ( \frac{5}{14} ) = 0.940$ Step2. 不斷計算資訊獲利( 找亂度比較低attribute的 )，選擇最大值當作根結點 Outlook Outlook = Sunny $$N_\oplus = 2, N_\ominus = 3, N_{Sunny} = 5$$ $$Entropy(S_{Sunny}) = -(\frac{2}{5})\cdot \log_2(\frac{2}{5}) - (\frac{3}{5}) \cdot \log_2(\frac{3}{5}) = 0.971$$ Outlook = Overcast $$N_\oplus = 4, N_\ominus = 0, N_{Overcast} = 4$$ $$Entropy(S_{Overcast}) = -(\frac{4}{4})\cdot \log_2(\frac{4}{4}) - (\frac{0}{4}) \cdot \log_2(\frac{0}{4}) = 0.0$$ Outlook = Rain $$N_\oplus = 3, N_\ominus = 2, N_{Rain} = 5$$ $$Entropy(S_{Rain}) = -(\frac{3}{5})\cdot \log_2(\frac{3}{5}) - (\frac{2}{5}) \cdot \log_2(\frac{2}{5}) = 0.971$$ 計算環境因素的 Outlook 之資訊獲利 $$Gain(S, Outlook) = Entropy(S) - (N_{Sunny} / N_{total}) * Entropy(S_{Sunny})$$ $$ - (N_{Overcast} / N_{total}) * Entropy(S_{Overcast})$$ $$ - (N_{Rain} / N_{total} ) * Entropy(S_{Rain})$$ $$\Rightarrow 0.940 - (5/14) \cdot 0.971 - (4/14) \cdot 0.00 - (5/14) \cdot 0.971 = 0.246$$ Temperature Repeat process over { Hot, Mild, Cool } $$ Gain( S, Temperature ) = 0.029 $$ Humidity Repeat process over { High, Normal } $$ Gain( S, Humidity ) = 0.151 $$ Wind Repeat process over { Weak, Strong } $$ Gain( S, Wind ) = 0.048 $$ 再來，我們要找到最佳的資訊獲利( Information gain )，其中： $$Gain(S, Outlook) = 0.246$$ $$ Gain( S, Temperature ) = 0.029 $$ $$ Gain( S, Humidity ) = 0.151 $$ $$ Gain( S, Wind ) = 0.048 $$ 從亂度的點看來，似乎Outlook的亂度最低( 與宇亂度相減後剩餘比較多資訊獲利 )，所以我們選擇Outlook作為我們根結點( root node )，如下圖： 選擇了Outlook做為決策樹的根結點後，緊接著，我們可以將三種不同的Outlook作為分支，其中特別的是，Overcast狀態之中( 上圖中間綠色部分 )，全部皆為開心狀態( Positive outcome )，所以可以直接決定Overcast輸出為開心( Positive )。 Step 2. Conti. - 選擇下一個節點( 子樹的根結點 )( 從何子節點開始建子樹？ I don&#39;t know yet. ) Same steps as earlier but only examples sorted to the node are used in Gain computations.( 無法理解 ) 選一個點( 隨機？ )繼續建子樹 Outlook = Sunny $$Gain(S_{Sunny}, Humidity) = 0.97 - (3/5) \cdot 0 - (2/5) \cdot 0 = 0.97 bits$$ $$Gain(S_{Sunny}, Temperature) = 0.97 - (2/5) \cdot 0 - (2/5) \cdot 1 - (1/5) \cdot 0 = 0.57 bits$$ $$Gain(S_{Sunny}, Wind) = 0.97 - (2/5) \cdot 1 - (3/5) \cdot 0.918 = 0.019 bits$$ 由上式可以看出來Humidity的亂度最小，所以選擇之為此子樹的根。 Final Decision Tree 熵、亂度 (Entropy) 介紹在資訊理論中，熵被用來衡量一個隨機變數出現的期望值(機率與統計)。它代表了在被接收之前，訊號傳輸過程中損失的資訊量，又被稱為資訊熵。熵是對不確定性的測量。在資訊界，熵越高則能傳輸越多的資訊( 資訊越多意味著有更多的可能性 )，熵越低則意味著傳輸的資訊越少( 資訊越少意味著有更少的可能性 )。 如果有一枚理想的硬幣，其出現正面和反面的機會相等，則拋硬幣事件的熵等於其能夠達到的最大值。我們無法知道下一個硬幣拋擲的結果是什麼，因此每一次拋硬幣都是不可預測的。( 越是不可預測的結果 $\rightarrow$ 亂度越大，而這種結果，正是造成人類選擇障礙的原因，所以我們希望熵越低越好，我們可以立即做出判斷 ) $Ex1.$使用一枚正常硬幣進行拋擲，這個事件的熵是一位元，若進行n次獨立實驗，則熵為$n$，因為可以用長度為 $n$ 的位元流表示。但是如果一枚硬幣的兩面完全相同，那個這個系列拋硬幣事件的熵等於零，因為結果能被準確預測。 $Ex2.$$Let \; y \; be \; a \; Boolean \; function, and \; let \; P \; denote \; Probability.$ What is the most pure (亂度低) probability distribution? $$P(y = 0) = 1, P(y = 1) = 0$$ $$P(y = 0) = 0, P(y = 1) = 1$$ What is the most impure (亂度高) probability distribution? $$P(y = 0) = 0.5, P(y = 1) = 0.5$$ 意同於最大的亂度。 定義首先，我們可以先從簡單的看討當目前的結果最多只有兩種情況，如拋硬幣，最多只有正面或是反面，下圖$x$軸$P_\oplus$代表擲出正面的機率函數，而$y$軸則是對應的熵值，而$P_\ominus$的機率軸則是會隨著$P_\oplus$下降而上升( 兩者互補 )，但是對應到的熵值會一樣大。 $S$ is a sample of training examples( 隨機變量 ). 當今天的結果只有正與反 ( 與硬幣一樣 )時，觀察目前的隨機變量 我們令： $P_\oplus$ ( 就目前隨機變數產生的機率 ) is the portion of the positive examples ( 正面 ) in $S$. $P_\ominus$ ( 就目前隨機變數產生的機率 ) is the portion of the negative examples ( 反面 ) in $S$. Entropy ( 熵 ) measures the impurity ( 亂度 ) of $S$. 我們先定義熵值 ( Entropy ) 如下： $$ Entropy( S ) = E( I( S ) ) = E(- \ln ( P ( S ) ) ) $$ 其中，$E$為期望函數，$I( S )$是 $S$ 的資訊量（又稱為資訊本體），$I( S )$也是一個隨機變數。 所以在取硬幣的樣本( $S$ )完後，我們可以將熵值寫成： $$ Entropy( S ) = \sum_{i = 1}^{2} P(S_i)I(S_i)$$ $$ \Rightarrow -\sum_{i = 1}^{2} P(S_i)\log_{2} P(S_i) $$ $$ \Rightarrow -P_{\oplus}\log_2 P_{\oplus} - P_{\ominus}\log_2 P_{\ominus}$$ ＜Note＞ $$\sum_{i = 1}^N P_i = 1 \; and \; 0 \leq P_i \leq 1 $$ 推廣至一般式 當取自有限的樣本時，熵的公式可以表示為： $$H(X) = \sum _{i} P(x_i) \, I(x_i)=-\sum_i P(x_i)\log _b P(x_i)$$ 在這裏 $b$ 通常是$2$,自然常數 $e$，或是$10$。當$b = 2$，熵的單位是$bit$；當$b = e$，熵的單位是$nat$；而當$b = 10$,熵的單位是$Hart$。 ＜Note＞ 定義當$P_i = 0$時，對於一些 $i$ 值，對應的被加數 $0 \log_b 0$ 的值將會是 $0$，這與極限一致。 $$ \Rightarrow \lim_{p\to0+} ( p\log p ) = 0 $$ CART (Classification and Regression Tree) 見 Mr&#39; opengate - AI - Ch14 機器學習(2), 決策樹 Decision Tree 決策樹學習的常見問題 避免過度適配資料( Prevent Overfitting )首先，相較於很冗長的樹，在機器學習中其實比較偏向於比較矮的樹，然而，為何？我們可以由Occam’s Razor ( 奧坎剃刀 )得知，若有兩個假說同時都能解釋該現象，我們偏向於比較沒那麼嚴個的假說( 可以表達比較廣的概念 )。 過度配適是指模型對於範例的過度訓練，導致模型記住的不是訓練資料的一般特性，反而是訓練資料的局部特性。對測試樣本的分類將會變得很不精確。 ＜注意＞通常過度適配發生在訓練範例含有雜訊和離異值時，但當訓練數據沒有雜訊時，過度適配也有可能發生，特別是當訓練範例的數量太少，使得某一些屬性「恰巧」可以很好地分割目前的訓練範例，但卻與實際的狀況並無太多關係。 解決方案：修剪決策樹移除不可信賴的分支 事前修剪 (Prepruning) : 透過決策樹不再增長的方式來達到修剪的目的。選擇一個合適的臨界值往往很困難。 事後修剪 (Postpruning) : 子樹置換 (Subtree Replacement)：選擇某個子樹，並用單個樹葉來置換它。 子樹提升 (Subtree Raising)： 合併連續值屬性透過動態地定義新的離散值屬性來實現，即先把連續值屬性的值域分割為離散的區間集合，或設定門檻值以進行二分法。 屬性選擇指標的其他度量標準 訊息獲利 : 趨向於包含多個值的屬性 獲利比率 : 會產生不平均的分割，也就是分割的一邊會非常小於另一邊 吉尼係數 : 傾向於包含多個值的屬性，當類別個數很多時會有困難，傾向那些會導致平衡切割並且兩邊均為純粹的測試 ＜尚有其他的度量標準，也都各有利弊＞ 例題 A data set has 4 Boolean variables. What is the maximum number of leaves in a decision tree? $2^4$ To each leaf in the decision, the number of corresponding rule is 1 If a decision tree achieves 100% accuracy on the training set, then it will also get 100% accuracy on the test set? No Using information gain to pick attributes, decision tree learning can be considered A* search algorithm. No A decision tree can describe any Boolean function? Yes 補充 C4.5 演算法 C4.5演算法利用屬性的獲利比率(Gain Ratio)克服問題，獲利比率是資訊獲利正規化後的結果。求算某屬性A的獲利比率時除資訊獲 利外，尚需計算該屬性的分割資訊值(Split Information) : SplitInfoA(S)=∑t∈T|Sj||S|×log2|Sj||S| C4.5的改善： 對連續屬性的處理 改善ID3傾向選擇擁有許多不同數值但不具意義的屬性：之所以使用獲利比率(Gain Ratio)，是因為ID3演算法所使用的資訊獲利會傾向選擇擁有許多不同數值的屬性，例如：若依學生學號(獨一無二的屬性)進行分割，會產生出許多分支，且每一個分支都是很單一的結果，其資訊獲利會最大。但這個屬性對於建立決策樹是沒有意義的。 C5.0 演算法 C5.0 是 C4.5的商業改進版，可應用於海量資料集合上之分類。主要在執行準確度和記憶體耗用方面做了改進。因其採用Boosting方式來提高模型準確率，且佔用系統資源與記憶體較少，所以計算速度較快。其所使用的演算法沒有被公開。 C5.0 的優點： C5.0模型在面對遺漏值時非常穩定。 C5.0模型不需要很長的訓練次數。 C5.0模型比較其他類型的模型易於理解。 C5.0的增強技術提高分類的精度。 參考 Mr&#39; opengate - AI - Ch14 機器學習(2), 決策樹 Decision Tree Wiki - 熵 - 資訊理論 奧坎剃刀]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Decision Tree Lrearning</tag>
        <tag>Data Mining</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Longest Palindromic Substring (Manacher’s Algorithm)]]></title>
    <url>%2Fblog%2F2018%2F03%2F25%2FLongest-Palindromic-Substring-Manacher%E2%80%99s-Algorithm%2F</url>
    <content type="text"><![CDATA[Manacher&#39;s Algorithm 使用了Gusfield&#39;s Algorithm(Z algorithm)的概念，使得時間複雜度為 O(N) 。 $Z$ 陣列 $Z[i]$ 是指以 $String[i]$ 為中心的最長迴文，從中心到外端的長度，也就是說 $$String[i \ldots i-Z(i)+1] = String[i \ldots i+Z(i)-1]$$ 呈鏡面對稱。 步驟 Step1. 而這種方式無法記錄偶數長度的迴文。解決辦法是：在開頭和結尾與每個字元中間，同時插入一個沒出現過的字元( # )，如此就只剩下奇數長度的迴文了，而且也能記錄原先偶數長度的迴文。 123456 | 10 12 14 16 | 0 1 2 3 4 5 6 7 8 9 11 13 15--+-----------------------------------s | a b a a b a a bs&apos;| # a # b # a # a # b # a # a # b #Z | 1 2 1 4 1 2 7 2 1 8 1 2 5 2 1 2 1 (Step2之後會講解如何計算) Step 2宣告一個陣列 $Z[n]$ ： 其中 $n$為 $String$ 的長度。$Z[i]$ 表示以 $i$ 為中心的最長回文串長度。續上例： 1234Z(0)=1：.，由中心可以左右延伸長度1。Z(1)=2：.a.，由中心可以左右延伸長度2。Z(2)=1：.，由中心可以左右延伸長度1。Z(3)=4：.a.b.a.，由中心可以左右延伸長度4。 宣告變量 $Cur$ ：表示當前回文串最長的中心的下標（current position），初值為0。 宣告變量 $Right$ ： 表示以 $Cur$ 為中心的回文串最右一個字符所處位置。如下： Step 3開始計算 $Z[i]$ ，是運用已經算好的 $Z[j]$ ， $j &lt; i$ 。也就是指某一段已經算好的 $$String[j \ldots j-z(j)+1] = String[j \ldots j+z(j)-1]$$ 。首先找出有覆蓋到 $String[i]$ 的 $String[j \ldots j+Z[j-1]]$ 是哪一段，而且 $j+Z[j]-1$ 越右邊越好。 所以我們使用剛剛所宣告的 $Cur$ 與 $Right$ 紀錄目前能跨越最右邊的中心點在哪。 $String ：$ 再來會分成兩種情況： Case1如果 $Right$ 不能覆蓋 $String[i]$ ，表示已經算好的部份都派不上用場。從 $String[i+1]$ 與 $String[i-1]$ 開始比對，逐字比下去。 $String ：$ Case2如果 $Right$ 能覆蓋 $String[i]$，表示 $String[i]$ 也會出現在 $String[j \ldots j-Z[j]+1]$ 之中，把 $i$ 鏡射到對應的位置 $i&#39;$ (出現在 $String[j \ldots j-Z[j]+1]$的位置)。接著運用 $Z[i&#39;]$ ，也就是指 $String[i&#39; \ldots i&#39;-Z[i&#39;]+1] = String[i&#39; \ldots i&#39;+Z(i&#39;)-1]$ ，再看看是否要繼續比對字串，會分成三種子情況： Subcase1若 $String[i \ldots i+z(i&#39;)-1]$ 短少於 $Right$，那就可以直接賦予 $Z[i]$ 與 $Z(i&#39;)$ 一樣的值。 Subcase2若 $String[i \ldots i+Z[i&#39;] -1]$ 剛好貼齊於 $Right$ ，那就必須檢查未確定的部分，直接從 $String[i+Z[i&#39;]]$ 與 $String[i-Z[i&#39;]]$ 繼續比對，逐字比下去。 Subcase3若 $String[i \ldots i+Z[i&#39;]-1]$ 突出了 $Right$，根據 $Z[j]$ 可知 $String[j-Z[j]]$ 與 $String[j+Z[j]]$ 一定是不同字元，根據 $Z[i&#39;]$ 可知 $String[j-Z[j]]$ 與其鏡射位置是相同字元。對於 $i$ 來說， $String[j+Z[j]]$ 與其鏡射位置就會是不同字元，不可能形成更長的迴文，因此可以直接算出 $Z[i]$ 的值，就是 $j+z[j]-i$ 。 範例程式Palindrome - 演算法筆記_112345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364char t[1001]; // 原字串char s[1001 * 2]; // 穿插特殊字元之後的tint z[1001 * 2], L, R; // 源自Gusfield's Algorithm // 由a往左、由b往右，對稱地作字元比對。int extend(int a, int b)&#123; int i = 0; while (a-i&gt;=0 &amp;&amp; b+i&lt;N &amp;&amp; s[a-i] == s[b+i]) i++; return i;&#125; void longest_palindromic_substring()&#123; int N = strlen(t); // t穿插特殊字元，存放到s。 // （實際上不會這麼做，都是細算索引值。） memset(s, '.', N*2+1); for (int i=0; i&lt;N; ++i) s[i*2+1] = t[i]; N = N*2+1;// s[N] = '\0'; // 可做可不做 // Manacher's Algorithm z[0] = 1; L = R = 0; for (int i=1; i&lt;N; ++i) &#123; int ii = L - (i - L); // i的映射位置 int n = R + 1 - i; if (i &gt; R) &#123; z[i] = extend(i, i); L = i; R = i + z[i] - 1; &#125; else if (z[ii] == n) &#123; z[i] = n + extend(i-n, i+n); L = i; R = i + z[i] - 1; &#125; else &#123; z[i] = min(z[ii], n); &#125; &#125; // 尋找最長迴文子字串的長度。 int n = 0, p = 0; for (int i=0; i&lt;N; ++i) if (z[i] &gt; n) n = z[p = i]; // 記得去掉特殊字元。 cout &lt;&lt; "最長迴文子字串的長度是" &lt;&lt; (n-1) / 2; // 印出最長迴文子字串，記得別印特殊字元。 for (int i=p-z[p]+1; i&lt;=p+z[p]-1; ++i) if (i &amp; 1) cout &lt;&lt; s[i];&#125; Palindrome - 演算法筆記_21234567891011121314151617181920212223242526272829303132char t[1001];char s[1001 * 2];int z[1001 * 2]; void longest_palindromic_substring()&#123; // t穿插特殊字元，存放到s。 int n = strlen(t); int N = n * 2 + 1; memset(s, '.', N); for (int i=0; i&lt;n; ++i) s[i*2+1] = t[i];// s[N] = '\0'; // z[0] = 1; // 無須使用，無須計算。 int L = 0, R = 0; for (int i=1; i&lt;N; ++i) // 從z[1]開始 &#123; z[i] = (R &gt; i) ? min(z[2*L-i], R-i) : 1; while (i-z[i] &gt;= 0 &amp;&amp; i+z[i] &lt; N &amp;&amp; s[i-z[i]] == s[i+z[i]]) z[i]++; if (i+z[i] &gt; R) L = i, R = i+z[i]; &#125; // 尋找最長迴文子字串的長度 int n = 0, p = 0; for (int i=1; i&lt;N; ++i) // 從z[1]開始 if (z[i] &gt; n) n = z[p = i]; cout &lt;&lt; "最長迴文子字串的長度是" &lt;&lt; (n-1) / 2;&#125; 相關題目 Timus-1297 LeetCode 參考 Manacher’s Algorithm - Simon的網路人工智慧實驗室 Palindrome - 演算法筆記]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>String</tag>
        <tag>Palindromic</tag>
        <tag>Z Algorithm</tag>
        <tag>Substring</tag>
        <tag>Manacher&#39;s Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有關字串的名詞解釋]]></title>
    <url>%2Fblog%2F2018%2F03%2F21%2F%E6%9C%89%E9%97%9C%E5%AD%97%E4%B8%B2%E7%9A%84%E5%90%8D%E8%A9%9E%E8%A7%A3%E9%87%8B%2F</url>
    <content type="text"><![CDATA[字元 (character)： 孤單的一個符號。’7’,’1’, ’ 阿’, ’2’, ’ a’, ’ X’ 字元集 (Alphabet)： 由字元組成的集合，通常會用$\sum$表示。 字串 (String)： 由字元集中的字元構成的序列。”7122” 子字串 (Substring)： 字串中的一段連續字元。”71” in ”7122” 子序列 (Subsequence)： 字串中不需連續的一斷字元。”72” in ”7122” 前綴 (Prefix)： 一個子字串包含第一個字元。”7”, ”71”, ”712”, ”7122” in ”7122”，在這裡所有文章我會命名為前總和，方便閱讀。 後綴 (Suffix)： 一個子字串包含最後一個字元。”2”, ”22”, ”122”, ”7122” in ”7122”，，在這裡所有文章我會命名為後總和，方便閱讀。 字典序 (Alphabetical Order)： 定義字串間的大小。先定義字元間的大小：$$’\,’ &lt; ’a’ &lt; ’b’ &lt; ’c’ &lt; ’d’ &lt; …&lt; ’z’$$通常就是照著 ASCII 碼的編排順序，要注意的是 空字元 比其他字元都小 接下來從第一個位置一位一位比對，由左而右比對方小的就是比較小的字串。 後綴數組 (Suffix Array)： 將一個字串的所有後綴(後總和) ，照字典序排序後，所得的名次陣列。$$Sa[i]: 第i個後綴$$ 排名數組 (Rank Array)： 為後綴數組的逆數組。$$Ra[i]: 第 i 個後綴是第幾名$$ 最長共同前綴 (Longest Common Prefix)： 兩個字串，從第一位一位一位比對，直到不一樣就停止 $ex:$ ’712221212’ 和’712222222’ 的LCP(最長共同前綴)：’71222’。 lcp(I, J)： 對於一個字串，他的第 I 個後綴和第 J 個後綴的 LCP 有多長 LCP(I, J)： 對於一個字串，他的第 I 名後綴與第 J 名後綴的 LCP 有多長 height[i]： 對於一個字串，LCP(i − 1, i) h[i]： 對於一個字串，LCP(Ra[i] − 1, Ra[i]) 參考 建國中學 2012 年資訊能力競賽培訓講義 - 08]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Z - algorithm]]></title>
    <url>%2Fblog%2F2018%2F03%2F19%2FZ-algorithm%2F</url>
    <content type="text"><![CDATA[這個演算法可以線性時間在一段文本(text) 裡面找到所有我們欲求的段落(pattern)。 今天，當我們的文本(text)的長度為 $n$ 且欲求的段落(pattern)為 $m$時 ，搜尋只需要線性長度的時間 $O(m+n)$ 即可，雖然這個演算法需要的空間(space complexity)與時間複雜度(time complexity)都與KMP algorithm一致，但是這個演算法比起KMP algoritjm還要容易了解。 KMP algorithm：每個前綴與其後綴的次長共同前綴（最長的後綴） Z algorithm：每個後綴與母字串的最長共同前綴（單純的長度） 首先，我們需要一個 $Z$陣列($Z$ array) $Z$陣列當我們將欲檢索的文本存為一個字串 $str[0\ldots n-1]$ 時，同時也建立一個與字串一樣長的$Z$陣列。 在$Z$陣列中，第 $i$ 元素紀錄「最長共同前總和 (Longest Common Prefix)的長度」，而 LCP 的長度 是由「從 $i$ 開始的後總和 (Postfix)」與「該文本」共同決定。 ( 注意： $Z[0]$ 毫無意義可言，因為從第0個開始的後總和(Postfix) 必與原本的文本字串相同。 ) 大致上我們可以看成如下的函式： $Ex.$ 123Index 0 1 2 3 4 5 6 7 8 9 10 11 Text a a b c a a b x a a a zZ values 1 0 0 3 1 0 0 2 2 1 0 $More$ $ex.$ 12345678str = &quot;aaaaaa&quot;Z[] = &#123;x, 5, 4, 3, 2, 1&#125;str = &quot;aabaacd&quot;Z[] = &#123;x, 1, 0, 2, 1, 0, 0&#125;str = &quot;abababab&quot;Z[] = &#123;x, 0, 6, 0, 4, 0, 2, 0&#125; $Z$ 陣列如何幫助演算法加速?這個演算法的想法是將段落(pattern)與文本字串(text string)連接起來，若視段落(pattern)為「P」，視文本字串(text string)為「T」，並加上一個從未在段落與文本中出現過的字元`「\$」再產生出如「P$T」的字串。 最後，我們再產生一個屬於「P$T」的 Z陣列，在 Z陣列之中，若該 Z值等於段落(pattern)的長度，段落出現在該處。 12345678910Example:Pattern P = &quot;aab&quot;, Text T = &quot;baabaa&quot;The concatenated string is&quot;a, a, b, $, b, a, a ,b ,a, a&quot;.Z array for above concatenated string is &#123;x, 1, 0, 0, 0, 3, 1, 0, 2, 1&#125;. ^Since length of pattern is 3, the value 3 in Z array indicates presence of pattern. 如何建立 $Z$陣列最簡單的就是使用兩個迴圈，外層迴圈將整個「P\$T」跑過一遍，內層迴圈則是看看到底 i 位置的後總和與「P$T」的LCP長度為何。 $Time$ $complexity:$ $$O(n^2)$$ 我們當然可以使用另一種方法讓建立陣列的時間複雜度降低。 此演算法的關鍵在於要維護一個區間$[L \ldots R]$，$R$ 的位置代表由 $L$ 處之後可以和整個字串最長的前總和重疊到的最後一個位置( 換句話說：$[L \ldots R]$是整個字串的前綴子字串 )，若完全不重疊，則 $L$ 與 $R$相等。 1234Index 0 1 2 3 4 5 6 7 8 9 10 11 Text a a b $ a a b x a a a zZ values 1 0 0 3 1 0 0 2 2 1 0 ========= ^L ^R 步驟 ($i$ 為當前位置) 若 $i &gt; R$ ，就代表當前 $i$ 沒有經過任何「P\$S」的前綴子字串，所以重置 $L$ 與 $R$ 的位置($L = i, R = i$)，經由比對「P\$S」的前綴與 $i$ 之後的前綴，並找出最長的子字串($R$ 的位置)，計算新的 $L$ 與 $R$ 的位置，也一併將 $Z[i]$值算出來($= R - L + 1$)。 若 $i \leq R$ ，令 $K = i - L$ ，再來我們知道 $Z[i] \geq min(Z[K], R-i+1)$ 因為$String[i \ldots]$與$String[K\ldots]$共同前$R-i+1$個字元必然為[P\$T]的前綴子字串。現在有兩種情形會發生： case1： 若$Z[K] &lt; R-i+1$ ，代表沒有任何「P\$S」的前綴子字串 從 $i$ 位置開始(否則 $Z[K]$ 的值會更大)，所以也意味著$Z[i] = Z[K]$，還有區間$[L\ldots R]$不變。 case2： 若$Z[K] \geq R-i+1$，代表$String[i \ldots]$可以和$String[0\ldots]$ 繼續比對相同的字元，也就意味有可能拓展$[L \ldots R]$ 區間，因此，我們會設 $L = i$ ，接著從 $R$ 之後開始繼續比對「P\$S」的前綴子字串，最後我們會得到新的$R$，並更新$[L \ldots R]$ 區間與計算 $Z[i]$ $( = R - L + 1)$。 想要了解上述的演算法可以經由這個連結觀看動畫。 小視窗 如果一個位置 $i$ 位於之前比過的那段 $[L, R]$ 當中，他是否跟 $Z[i − L]$ 相同呢？我們可以分成三種情形： 要比的後綴根本不在以前比過的範圍$[L, R]$內 → 就去比吧！ 要比的後綴在以前比過的範圍$[L, R]$但長度未知 → 還是去比吧！ 要比的後綴在以前比過的範圍$[L, R]$但長度已知 → 直接記錄囉！ 程式碼實作 台大資工PPT by nkng12345678910void z_build(const char *S, int *Z) &#123; Z[0] = 0; int bst = 0; for(int i = 1; S[i]; i++) &#123; if(Z[bst] + bst &lt; i) Z[i] = 0; else Z[i] = min(Z[bst]+bst-i, Z[i-bst]); while(S[Z[i]] == S[i+Z[i]]) Z[i]++; if(Z[i] + i &gt; Z[bst] + bst) bst = i; &#125;&#125; Z algorithm - GeeksforGeeks123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990// A C++ program that implements Z algorithm for pattern searching#include&lt;iostream&gt;using namespace std; void getZarr(string str, int Z[]); // prints all occurrences of pattern in text using Z algovoid search(string text, string pattern)&#123; // Create concatenated string "P$T" string concat = pattern + "$" + text; int l = concat.length(); // Construct Z array int Z[l]; getZarr(concat, Z); // now looping through Z array for matching condition for (int i = 0; i &lt; l; ++i) &#123; // if Z[i] (matched region) is equal to pattern // length we got the pattern if (Z[i] == pattern.length()) cout &lt;&lt; "Pattern found at index " &lt;&lt; i - pattern.length() -1 &lt;&lt; endl; &#125;&#125; // Fills Z array for given string str[]void getZarr(string str, int Z[])&#123; int n = str.length(); int L, R, k; // [L,R] make a window which matches with prefix of s L = R = 0; for (int i = 1; i &lt; n; ++i) &#123; // if i&gt;R nothing matches so we will calculate. // Z[i] using naive way. if (i &gt; R) &#123; L = R = i; // R-L = 0 in starting, so it will start // checking from 0'th index. For example, // for "ababab" and i = 1, the value of R // remains 0 and Z[i] becomes 0. For string // "aaaaaa" and i = 1, Z[i] and R become 5 while (R&lt;n &amp;&amp; str[R-L] == str[R]) R++; Z[i] = R-L; R--; &#125; else &#123; // k = i-L so k corresponds to number which // matches in [L,R] interval. k = i-L; // if Z[k] is less than remaining interval // then Z[i] will be equal to Z[k]. // For example, str = "ababab", i = 3, R = 5 // and L = 2 if (Z[k] &lt; R-i+1) Z[i] = Z[k]; // For example str = "aaaaaa" and i = 2, R is 5, // L is 0 else &#123; // else start from R and check manually L = i; while (R&lt;n &amp;&amp; str[R-L] == str[R]) R++; Z[i] = R-L; R--; &#125; &#125; &#125;&#125; // Driver programint main()&#123; string text = "GEEKS FOR GEEKS"; string pattern = "GEEK"; search(text, pattern); return 0;&#125; 建國中學 2012 年資訊能力競賽培訓講義 - 08123456789101112void Z_maker( int z[], char s[], int n )&#123; z[0] = n; int L = 0, R = 0, i, x; for( i = 1 ; i &lt; n ; i++ )&#123; if( R &lt; i || z[i-L] &gt;= R-i+1 )&#123; R &lt; i ? x = i : x = R+1; while( x &lt; n &amp;&amp; s[x] == s[x-i] ) x++; z[i] = x-i; if( i &lt; x )&#123; L = i; R = x-1; &#125; &#125; else z[i] = z[i-L]; &#125;&#125; Z algorithm - codeforces12345678910111213141516int L = 0, R = 0;for (int i = 1; i &lt; n; i++) &#123; if (i &gt; R) &#123; L = R = i; while (R &lt; n &amp;&amp; s[R-L] == s[R]) R++; z[i] = R-L; R--; &#125; else &#123; int k = i-L; if (z[k] &lt; R-i+1) z[i] = z[k]; else &#123; L = i; while (R &lt; n &amp;&amp; s[R-L] == s[R]) R++; z[i] = R-L; R--; &#125; &#125;&#125; Z algorithm1 - 日月卦長的模板庫123456789inline void z_alg1(char *s,int len,int *z)&#123; int l=0,r=0; z[0]=len; for(int i=1;i&lt;len;++i)&#123; z[i]=r&gt;i?min(r-i+1,z[z[l]-(r-i+1)]):0; while(i+z[i]&lt;len&amp;&amp;s[z[i]]==s[i+z[i]])++z[i]; if(i+z[i]-1&gt;r)r=i+z[i]-1,l=i; &#125;&#125; Z algorithm2 - 日月卦長的模板庫123456789inline void z_alg2(char *s,int len,int *z)&#123; int l=0,r=0; z[0]=len; for(int i=1;i&lt;len;++i)&#123; z[i]=i&gt;r?0:(i-l+z[i-l]&lt;z[l]?z[i-l]:r-i+1); while(i+z[i]&lt;len&amp;&amp;s[i+z[i]]==s[z[i]])++z[i]; if(i+z[i]-1&gt;r)r=i+z[i]-1,l=i; &#125;&#125; 培訓-4 字串- tioj12345678910void z_build(const char* S,int *z)&#123; z[0]=0; int bst=0; for(int i=1;S[i];i++)&#123; if(z[bst]+bst&lt;i) z[i]=0; else z[i]=std::min(z[bst]+bst−i,z[i−bst]); while(S[z[i]]==S[i+z[i]]) z[i]++; if(z[i]+i&gt;z[bst]+bst) bst=i; &#125;&#125; 例題 TIOJ 1725_Z algorithm_Massacre at Camp Happy 參考 Z algorithm - GeeksforGeeks 建國中學 2012 年資訊能力競賽培訓講義 - 08 培訓-4 字串- tioj 台大資工講義 by nkng Z algorithm - codeforces Gusfield algorithm - momo funny codes Z algorithm - 日月卦長的模板庫 待補充 KMP 字串比對演算法http://mropengate.blogspot.tw/2016/01/leetcode-kmpimplement-strstr.html]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>String</tag>
        <tag>Z Algorithm</tag>
        <tag>Substring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[泰勒級數]]></title>
    <url>%2Fblog%2F2018%2F03%2F16%2F%E6%B3%B0%E5%8B%92%E7%B4%9A%E6%95%B8%2F</url>
    <content type="text"><![CDATA[在數學中，泰勒級數（英語：Taylor series）用無限項連加式——級數來表示一個函數，這些相加的項由函數在某一點的導數求得。泰勒級數是以於1715年發表了泰勒公式的英國數學家布魯克·泰勒（Sir Brook Taylor）來命名的。通過函數在自變量零點的導數求得的泰勒級數又叫做麥克勞林級數，以蘇格蘭數學家科林·麥克勞林的名字命名。 拉格朗日在1797年之前，最先提出帶有餘項的現在形式的泰勒定理。實際應用中，泰勒級數需要截斷，只取有限項，可以用泰勒定理估算這種近似的誤差。一個函數的有限項的泰勒級數叫做泰勒多項式。一個函數的泰勒級數是其泰勒多項式的極限（如果存在極限）。即使泰勒級數在每點都收斂，函數與其泰勒級數也可能不相等。開區間（或複平面開片）上，與自身泰勒級數相等的函數稱為解析函數。 定義 在數學上，一個在實數或複數 $a$ 在 鄰域上的無窮可微實變函數或複變函數 $f(x) $的泰勒級數是如下的冪級數 (若與原函式相等時為解析函數)： $$f(x) \simeq \sum_{n=0}^{\infty }{\frac {f^{(n)}(a)}{n!}}(x-a)^{n}$$ 而 $ f^{(n)}(a) $表示函數 $f$ 在點 $ a$ 處的 $ n$ 階導數。如果 $ a=0$ ，那麼這個級數也可以被稱為麥克勞林級數。 而多項式函數 $f(x) $ 在 $ x = a$ 時，$n $ 階的泰勒展開式 $P_{n}(x)$ 是： $$P_{n}(x) = \sum_{i = 0}^{n} \frac{ f^{(i)}(a) }{ i! }\cdot \left(x-a \right)^{i}$$ 解析函數Read more-1 (wiki)，Read more-2 (wiki) 如果泰勒級數對於區間 $ (a-r,a+r) $中的所有 $ x$ 都收斂並且級數的和等於 $ f(x) $ ，那麼我們就稱函數 $ f(x)$ 為解析的（analytic）。若且唯若一個函數可以表示成為冪級數的形式時，它才是解析的。為了檢查級數是否收斂於 $ f(x) $，通常採用泰勒定理估計級數的餘項 (數值方法)。上面給出的冪級數展開式中的係數正好是泰勒級數中的係數。 泰勒級數的重要性體現在以下三個方面： 冪級數的求導和積分可以逐項進行，因此求和函數相對比較容易。 一個解析函數可被延伸為一個定義在複平面上的一個開片上的解析函數，並使得複分析這種手法可行。 泰勒級數可以用來近似計算函數的值。 對定值 x 而言，函數的精準度會隨著多項式的次數 n 的增加而增加。 對一個固定次數的多項式而言， 確度隨著 x 離開 x=0 處而遞減。 泰勒級數列表(常用) 注意：核函數 $ x$ 為 複數 時它們依然成立！ 幾何級數(等比數列) $$\frac {1}{1-x} = \sum _{n=0}^{\infty }x^{n}\quad \forall x:\left|x\right|&lt;1$$ 二項式定理 $$(1+x)^{\alpha }=\sum _{n=0}^{\infty }C^\alpha _n \cdot x^{n}\quad \forall x:\left|x\right|&lt;1,\forall \alpha \in \mathbb {C} $$ 指數函數 $$e^{x}=\sum _{n=0}^{\infty }{\frac {x^{n}}{n!}}\quad \forall x$$ $f(x) = e^x$ 在 $x = 0$ 的泰勒展開式。 當$n = 1$時，$P_{1}(x) = 1+ \frac{\left( e^0\right)&#39;}{1!}\cdot\left( x - 0 \right)^1$ 當$n = 2$時，$P_{2}(x) = 1+ \frac{\left( e^0\right)&#39;}{1!}\cdot\left( x - 0 \right)^1 + \frac{\left( e^0\right)&#39;&#39;}{2!}\cdot\left( x - 0 \right)^2$ 當$n = 3$時，$P_{3}(x) = 1+ \frac{\left( e^0\right)&#39;}{1!}\cdot\left( x - 0 \right)^1 + \frac{\left( e^0\right)&#39;&#39;}{2!}\cdot\left( x - 0 \right)^2 + \frac{\left( e^0\right)^{(3)}}{3!}\cdot\left( x - 0 \right)^3$ $...$ 自然對數 $$\ln(1+x)=\sum _{n=1}^{\infty }{\frac {(-1)^{n+1}}{n}}x^{n}\quad \forall x\in (-1,1]$$ 牛頓插值公式的淵源Read more-1(wiki)，Read more-2(wiki) 牛頓插值公式也叫做牛頓級數，由「牛頓 前向 差分方程」的項組成，得名於伊薩克·牛頓爵士。一般稱其為連續「泰勒展開」的離散對應。 差分差分，又名差分函數或差分運算，是數學中的一個概念。它將原函數 $f(x)$ 映射到 $f(x+a)-f(x+b)$ 。差分運算，相應於微分運算，是微積分中重要的一個概念。 定義前向差分的定義為： $$\Delta_{h}^{1}[f](x) = f(x + h) - f(x)$$ $$\Delta_{h}^{n}[f](x) = \Delta_{h}^{n-1}[f](x + h) - \Delta_{h}^{n-1}[f](x)$$ $, where $ $ h =$ $ &quot;x&quot;$ $一步的間距，若無下標h，那間距h = 1。$ 前向差分函數的前向差分通常簡稱為函數的差分。對於函數 $f(x)$ ，如果在等距節點： $$x_{k}=x_{0}+kh,(k=0,1,...,n)$$ $$\Delta f(x_{k})=f(x_{k+1})-f(x_{k})$$ 則稱 $\Delta f(x)$，函數在每個小區間上的增量 $y_{k+1}-y_{k}$ 為 $f(x)$ 一階差分。 後向差分對於函數 $f(x_{k})$，如果： $$\nabla f(x_{k})=f(x_{k})-f(x_{k-1})$$ 則稱 $\nabla f(x_{k})$ 為 $f(x)$ 的一階逆向差分。 階一階差分的 差分 為二階差分，二階差分的 差分 為三階差分，其餘類推。記： $\Delta ^{n}[f](x)$為 $f(x)$的 $n$ 階差分。 $$\Delta ^{n}[f](x)=\Delta {\Delta ^{n-1}[f](x)}$$ $$=\Delta ^{n-1}[f](x+1)-\Delta ^{n-1}[f](x)$$ 其中： $$\Delta ^{2}[f](x)=f(x+2)-2f(x+1)+f(x)$$ 前向差分有時候也稱作數列的二項式變換。 由上式，再根據數學歸納法，我們最後可以得到： $$\Delta^{n}[f](x)=\sum_{i=0}^{n}C_i^n\cdot(-1)^{n-i}\cdot f(x+i)$$ 均差均差（Divided differences）是遞歸除法過程。在 數值分析 中，也稱差商（Difference quotient），可用於計算牛頓多項式形式的多項式插值的係數。 定義給定n+1個數據點 $(x_0, y_0),\ldots,(x_{n}, y_{n})$ 前向均差：$$[y_\nu] = y_, \quad \nu \in {0, \ldots, n}$$ $$[y_\nu, \ldots, y_{\nu+j}] = \frac{[y_{\nu+1}, \ldots, y_{\nu+j}] - [y_\nu, \ldots, y_{\nu+j-1}]}{x_{\nu+j} - x_\nu}, \quad \nu \in { 0, \ldots, n-j}, j \in {1, \ldots, n}$$ $ex.$ $$[y_0] = y_0$$ $$[y_0,y_1] = \frac{y_1-y_0}{x_1-x_0}$$ $$[y_0,y_1,y_2] = \frac{\mathopen[y_1,y_2]-\mathopen[y_0,y_1]}{x_2-x_0}$$ $$[y_0,y_1,y_2,y_3] = \frac{\mathopen[y_1,y_2,y_3]-\mathopen[y_0,y_1,y_2]}{x_3-x_0}$$ $$\ldots$$ $$[y_0,y_1,\dots,y_n] = \frac{\mathopen[y_1,y_2,\dots,y_n]-\mathopen[y_0,y_1,\dots,y_{n-1}]}{x_n-x_0}$$ 為了使涉及的遞歸過程更加清楚，以列表形式展示均差的計算過程： 牛頓多項式的定義給定 $k+1$ 個數據點的集合 $(x_{0},y_{0}),\ldots ,(x_{k},y_{k})$。 如果對於 $\forall i,j \in {0,...,k},i \neq j$，滿足 $ x_{i}\neq x_{j}$，那麼應用牛頓插值公式所得到的牛頓插值多項式為 $$N(x):=\sum_{j=0}^{k}a_{j}n_{j}(x)$$ 其中每個 $n_{j}(x)$ 為牛頓基本多項式（或稱插值基函數），其表達式為 $$n_{j}(x):=\prod_{i=0}^{j-1}(x-x_{i})$$ 其中 $j&gt;0$，並且 $n_{0}(x)\equiv 1$。 係數 $a_{j}:=[y_{0},\ldots ,y_{j}]$，而 $[y_{0},\ldots ,y_{j}]$表示均差。 因此，牛頓多項式可以寫作： $$N(x)=[y_{0}]+[y_{0},y_{1}](x-x_{0})+\cdots +[y_{0},\ldots ,y_{k}](x-x_{0})(x-x_{1})\cdots (x-x_{k-1})$$ 參考 維基百科 - 差分 維基百科 - 泰勒級數 維基百科 - 牛頓插值法 中山大學 - 應數碩 林瑋玲]]></content>
      <categories>
        <category>Discrete Mathematics</category>
      </categories>
      <tags>
        <tag>Taylor Series</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[指對數]]></title>
    <url>%2Fblog%2F2018%2F03%2F15%2F%E6%8C%87%E5%B0%8D%E6%95%B8%2F</url>
    <content type="text"><![CDATA[&quot;$e^{x}$&quot; 緣起首先，要先從複利的公式開始說明： $$一年後的本利和 = \left(1+\frac{年利率}{期數} \right)^{期數}$$ 其中期數就是看多久複利一次。一個月複利一次的話期數就是12。 依上述所說，設 1 份借貸有 x 年利率，逐月複利話，則每月增加當前值的 $\frac{x}{12}$ 倍，每月總值都要乘以 $1 + \frac{x}{12}$，一年的總值為 $\left(1 + \frac{x}{12} \right)^{12}$，逐日複利的話，就是 $\left (1+ \frac{x}{365} \right)^{365}$。設年中時段數可為無限，則有如下最初由歐拉提出的指數函數定義： $$\lim_{n \to \infty}\left ( 1 + \frac{x}{n} \right )^{n}$$ 然後才真正的導出e這個數字，一開始存1元，如果年利率是100%，如果每分每秒都算利息，那麼一年後會得到的利息大約是2.71828，如果把算利息的區間縮到無限小，也就是期數變成無限大的話，就會得到 $$\lim_{n \to \infty}\left ( 1 + \frac{1}{n} \right )^{n} = e$$ 由上式我們則可以得到, $$\lim_{n \to \infty}\left ( 1 + \frac{x}{n} \right )^{n} = \lim_{n \to \infty} \left ( \left ( 1 + \frac{1}{\frac{n}{x}} \right )^{\frac{n}{x}} \right )^{x} \approx e^{x}$$ 其中， $$\lim_{n \to \infty} \left ( 1 + \frac{1}{\frac{n}{x}} \right )^{\frac{n}{x}} \approx e^{1} = e$$ 而這是它寫為 $e^{x}$ 的原因。 所以指數函數有基本的恆等式： $$e^{x+y} = e^{x} \cdot e^{y}$$ $$\parallel $$ $$\exp\left ( x + y \right ) = \exp\left ( x \right ) \cdot \exp\left ( y \right ) $$ 性質所以，正常指數該有的性質 $e$ 也都有具備，令 $\forall x, y\in \mathrm{R}$ ，則： $e^{0}=1$ $e^{1}=e$ $e^{x+y}=e^{x}e^{y}$ $e^{x \cdot y}=\left(e^{x}\right)^{y}$ $e^{-x}={1 \over e^{x}}$ 微分微分的時候需要下面這個式子： $$\lim_{n \to \infty} \left(1 + \frac{1}{n}\right) = \lim_{n \to \infty}\left(\left(1 + \frac{1}{\frac{n}{1}}\right)^{\frac{n}{1}}\right)^{\frac{1}{n}} \approx \lim_{n \to \infty} e^{\frac{1}{n}} \Rightarrow e^{\Delta x} \approx (1 + \Delta x)$$ 其中， $\lim_{n \to \infty} \left ( 1 + \frac{1}{\frac{n}{1}} \right )^{\frac{n}{1}} \approx e^{1} = e$ 當$n \to \infty$時 $\frac{1}{n}$ 可視為一個很小的量 $\Delta x$ ，也就是： $$\lim_{m \to 0} (1 + m ) \approx \lim_{m \to 0} e^{m}$$ $$(1 + 很小 ) \approx e^{很小}$$ $$(1 + \Delta x ) \approx e^{\Delta x}$$ 微分推導$$\Delta y = e^{x+\Delta x} - e^{x} = e^{\Delta x}\cdot e^{x} - 1\cdot e^{x} = (e^{\Delta x} - 1) e^{x}$$ 又因： $$e^{\Delta x} \approx (1 + \Delta x)$$ 所以： $$\Delta y \approx e^{x}\Delta x \rightarrow dy = e^{x}\cdot dx$$ 小結：$$de^{□} = e^{□}d□$$ $ex.$ $$de^{-x^2} = e^{-x^2}\cdot d(-x^2) = (-2x)\cdot e^{-x^2}\cdot dx$$ 一般化：$y = a^x $$\Rightarrow y = e^{\ln{a^{x}}} = e^{x\cdot\ln{a}} \Rightarrow $ (對 $y$ 作微分)$\Rightarrow dy= e^{x\cdot\ln{a}} \cdot \left ( x\cdot\ln{a} \right )$$\Rightarrow dy=a^x\cdot \ln a \cdot dx$ &quot;$e^{x}$&quot; 的反函數 對數函數，就是 $e^{x}$ 的反函數，也就是 $$y = \log_{e}{x} = \ln{x} \quad x = e^{y}$$ 定義尤拉定義自然對數為序列的極限： $$\ln (x) = \lim_{x\rightarrow \infty} n(x^{\frac{1}{n}}- 1)$$ 正式的定義為積分$\ln (a)$： $$\ln (a) = \int_1^a \frac{1}{x} dx$$ 對 &quot;$\ln{x}$&quot; 做微分 簡單地，我們可以推得： $y = \ln x $ $\Rightarrow x = e^y $ $\Rightarrow dx = e^y dy $$\Rightarrow dy = \frac{1}{e^y} dx = \frac{1}{x} dx $ (移&quot; $e^{y}$ &quot;項) Proof $\ln x = \int_1^x \frac{1}{x} dx$ $\frac{d}{dx}\ln x = \lim_{h \rightarrow 0} (\frac{\ln(x+h) - \ln x}{h})$ $\Leftrightarrow \lim_{h \rightarrow 0} (\frac{1}{h}\cdot \ln(\frac{x+h}{x}))$ $\Leftrightarrow \lim_{h \rightarrow 0} (\ln (1+\frac{h}{x})^{\frac{1}{h}})$ ＜Note＞：$Let \; u = \frac{h}{x} , h = u\cdot x \rightarrow h \; gose \; to \; 0 \; then \; u \; gose \; to \; 0$ $\Rightarrow \lim_{u \to 0} (\ln (1+u)^{\frac{1}{u\cdot x}} ) \Rightarrow \lim_{u \to 0} (\ln(1+u)^{\frac{1}{u}^\frac{1}{x}})$ $\Leftrightarrow \lim_{u \to 0} (\frac{1}{x} \cdot ln (1 + u)^{\frac{1}{u}})$ $\Leftrightarrow \frac{1}{x} \lim_{u \to 0} (\ln(1+u)^{\frac{1}{u}})$ ＜Note＞：$Let \; n = \frac{1}{u} \rightarrow u \; gose \; to \; 0 \; then \; n \; gose \; to \; \infty $ $\Rightarrow \frac{1}{x} lim_{n \to \infty} (\ln (1 + \frac{1}{n})^n)$ $\Leftrightarrow \frac{1}{x} \ln( \lim_{n \to \infty} (1 + \frac{1}{n})^n )$ $\Leftrightarrow \frac{1}{x} \ln e \Leftrightarrow \frac{1}{x}$ $\Leftrightarrow \frac{d}{dx} \int_1^x \frac{1}{t} dt $（微積分第一基本定理） $$\frac{d}{dx} \ln x = \frac{d}{dx} \int_1^x \frac{1}{t} dt \Leftrightarrow \ln x = \int_1^x \frac{1}{t} dt $$ 一般化：$y=\log_a x $ $\Rightarrow y = \frac{\ln{x}}{\ln{a}}$ $\Rightarrow dy=\frac{1}{x}\cdot \frac{1}{\ln a} \cdot dx$ &quot; $f \left( x\right) = x^x$ &quot;的微分 兩側取 &quot;$\ln$&quot;$$\ln \left( f \left( x\right) \right) = x \cdot \ln{x}$$ 對兩側微分$$\frac{f&#39;(x)}{f(x)} = \left( 1 \cdot \ln{x} \right) + \left( x \cdot \frac{1}{x}\right)$$ 對兩側乘上 &quot;$f(x)$&quot;$$f&#39;(x) = \left( \left( 1 \cdot \ln{x} \right) + \left( x \cdot \frac{1}{x}\right) \right) \cdot f(x)$$ $$\Rightarrow f&#39;(x) = \left( \ln{x} + 1 \right) \cdot \left( x^x \right)$$ 參考 成大微積分指對數函數的微分(第四週共筆) 維基百科 - e (數學常數) 維基百科 - 指數函數 中華科大 - PART 10：指數與對數微分公式彙整]]></content>
      <categories>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Exponent</tag>
        <tag>Logarithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MathJax 文法測試]]></title>
    <url>%2Fblog%2F2018%2F03%2F06%2FMathJax-test%2F</url>
    <content type="text"><![CDATA[Admin測試$$ \lim_{n \to \infty}\left ( 1 + \frac{1}{n} \right )^{n} $$]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>MathJax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一篇測試發文]]></title>
    <url>%2Fblog%2F2018%2F03%2F06%2F%E7%AC%AC%E4%B8%80%E7%AF%87%E6%B8%AC%E8%A9%A6%E7%99%BC%E6%96%87%2F</url>
    <content type="text"><![CDATA[H1H2H3H4H5H6]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>Mark Down</tag>
      </tags>
  </entry>
</search>
